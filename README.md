# ğŸ¦™ LlamaLens â€“ AI-Powered API Debugger  
**Built for FutureStack GenAI Hackathon**  
*By Swayam Prakash Sahu*  

---

## ğŸš€ Overview  

**LlamaLens** is an AI-powered **API Debugger** that helps developers instantly understand and fix issues in API responses, logs, or error messages.  

Just paste your API response or log snippet â€” and **LlamaLens**, powered by **Metaâ€™s Llama 4 (Scout 17B)** via **Cerebras Cloud**, analyzes it in real time, explains what went wrong in plain English, and suggests possible fixes.  

Containerized with **Docker**, itâ€™s portable, easy to run anywhere, and showcases integration of multiple sponsor technologies (Meta + Docker + Cerebras).  

---

## ğŸ’¡ Problem Statement  

Debugging APIs is time-consuming. Developers often face cryptic error messages, inconsistent logs, or poorly documented endpoints.  
LlamaLens acts as your **AI debugging companion**, simplifying the process using generative AI reasoning.  

---

## ğŸ¯ Key Features  

âœ… Paste any API response or log and get instant insights  
âœ… Human-readable explanation of the issue  
âœ… Fix suggestions, code hints, and API best practices  
âœ… Powered by **Meta Llama 4 (Scout 17B)** via **Cerebras Cloud SDK**  
âœ… Portable via **Docker MCP Gateway** â€“ runs anywhere in one command  
âœ… Streamlit UI for smooth local or web demo  

---

## ğŸ§  Tech Stack  

| Layer | Technology |
|-------|-------------|
| **AI Model** | Meta Llama 4 Scout 17B (Instruct) |
| **AI Platform** | Cerebras Cloud SDK |
| **Frontend/UI** | Streamlit |
| **Containerization** | Docker |
| **Language** | Python 3.10 |
| **Deployment (optional)** | Render / Hugging Face Spaces |

---

## ğŸ§© Architecture  

```
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚        User (Developer)     â”‚
          â”‚  Paste API response/logs    â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   Streamlit UI     â”‚
                â”‚  (app.py frontend) â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  llama_client.py   â”‚
                â”‚ Cerebras SDK calls â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   Cerebras Cloud â€“ Llama 4 Scout   â”‚
          â”‚   Metaâ€™s 17B Instruct Model        â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure  

```
llama-lens/
â”‚
â”œâ”€â”€ app.py                     # Streamlit UI
â”œâ”€â”€ llama_client.py             # Llama 4 Cerebras API wrapper
â”œâ”€â”€ utils.py                    # Helper utilities
â”œâ”€â”€ Dockerfile                  # Docker container setup
â”œâ”€â”€ requirements.txt            # Dependencies
â”œâ”€â”€ README.md                   # Project documentation
â””â”€â”€ assets/
    â””â”€â”€ architecture.png         # Architecture diagram (optional)
```

---

## âš™ï¸ Setup Instructions  

### 1ï¸âƒ£ Clone the Repository  

```bash
git clone https://github.com/yourusername/llama-lens.git
cd llama-lens
```

---

### 2ï¸âƒ£ Create and Activate Virtual Environment  

**Mac/Linux:**  
```bash
python3 -m venv venv
source venv/bin/activate
```

**Windows (PowerShell):**  
```bash
python -m venv venv
venv\Scripts\activate
```

---

### 3ï¸âƒ£ Install Dependencies  

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

---

### 4ï¸âƒ£ Set Up Environment Variable  

You need a **Cerebras Cloud API Key** (sign up on [Cerebras Cloud](https://cloud.cerebras.ai)).  

```bash
export CEREBRAS_API_KEY="your_cerebras_api_key_here"
```

*(On Windows PowerShell)*  
```bash
setx CEREBRAS_API_KEY "your_cerebras_api_key_here"
```

---

### 5ï¸âƒ£ Run the Application  

```bash
streamlit run app.py
```

Then open in your browser â†’  
ğŸ‘‰ **http://localhost:8501**

---

## ğŸ§ª How to Test the App  

Once the app loads, youâ€™ll see:  
> â€œğŸ¦™ LlamaLens â€“ AI-Powered API Debuggerâ€

Paste this into the text area:  

```json
{"error": "401 Unauthorized", "message": "Invalid API token"}
```

Click **Analyze with Llama ğŸ§ **

You should see something like:  
> The API returned a 401 Unauthorized error.  
> âœ… Fix: Check your authentication header or refresh your token.  

---

## ğŸ§  Backend Verification  

To verify Cerebras integration:  

Add a debug print inside `llama_client.py`:
```python
print("âœ… Calling Llama API via Cerebras...")
```

Run again â€” you should see this printed each time you click **Analyze**.

---

## ğŸ³ Run with Docker (Sponsor Track: Docker MCP)  

### Build the Image  

```bash
docker build -t llama-lens .
```

### Run the Container  

```bash
docker run -e CEREBRAS_API_KEY=$CEREBRAS_API_KEY -p 8501:8501 llama-lens
```

Then open â†’ [http://localhost:8501](http://localhost:8501)

This proves your app runs in a **portable, sponsor-compliant** containerized environment.  

---

## ğŸ§ª Health Check (Optional)  

You can run a quick backend test:  

```bash
python health_check.py
```

Output:  
```
âœ… Llama response: The API returned 404 Not Found. This means the requested endpoint does not exist...
```

---

## ğŸ§± Example Project Workflow  

1ï¸âƒ£ User pastes an API response or log in Streamlit UI  
2ï¸âƒ£ The app calls `call_llama()` â†’ sends request to Cerebras Cloud  
3ï¸âƒ£ Meta Llama 4 Scout processes and returns human-readable explanation  
4ï¸âƒ£ Streamlit displays suggested fixes and debug reasoning  

---

## ğŸ… Hackathon Deliverables  

| Item | Description |
|------|--------------|
| **GitHub Repo** | Contains code, commits, and README |
| **2-Minute Demo Video** | Show app usage, explanation, and Docker run |
| **(Optional)** Deployment | Host on Render / Hugging Face Spaces |
| **Sponsor Techs Used** | Meta Llama 4 + Cerebras SDK + Docker |

---

## ğŸ¥ Demo Video Script (Suggestion)  

1. **Intro (10 s)** â€“ â€œHi, Iâ€™m Swayam, and this is LlamaLens.â€  
2. **Show app** â€“ Paste API error â†’ click **Analyze**  
3. **Explain output** â€“ Llama suggests fix  
4. **Show Docker run** â€“ `docker build` + `docker run`  
5. **End** â€“ Show architecture diagram + GitHub link  

---

## ğŸ§  Design Principles  

- ğŸ§© Modular Code (UI, Logic, Helpers separated)  
- ğŸ” Secure â€“ API key via environment variable  
- âš¡ Fast â€“ Uses Cerebras streaming API  
- ğŸ³ Portable â€“ Dockerized for reproducibility  
- ğŸ§¹ Clean â€“ PEP 8 style and docstrings  

---

## ğŸ§° Dependencies  

| Library | Purpose |
|----------|----------|
| **Streamlit** | UI frontend |
| **Cerebras-Cloud-SDK** | Llama 4 API access |
| **Requests** | HTTP helper |
| **Python 3.10+** | Core runtime |

Install all via:  
```bash
pip install -r requirements.txt
```

---

## ğŸ’¬ Example Interaction  

**Input:**  
```json
{"status":500,"error":"Internal Server Error","message":"Cannot parse JSON input"}
```

**LlamaLens Output:**  
> The API returned a 500 error because the server couldnâ€™t parse the request body.  
> âœ… Fix: Ensure valid JSON formatting and `Content-Type: application/json` header.  

---

## ğŸ“¦ Future Improvements  

ğŸš€ Add support for file uploads (log files)  
ğŸ’¬ Integrate syntax-highlighted explanations  
ğŸ“Š Visualize frequent API issues using charts  
ğŸ”— Support multiple LLM providers (Cerebras, OpenAI, Anthropic)  

---

## ğŸ“œ License  

MIT License Â© 2025 Swayam Prakash Sahu  
